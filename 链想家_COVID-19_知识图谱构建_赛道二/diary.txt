## 2021 5 10 星期一
最近做公司合并稍微有点多余的时间，打算试试这个知识图谱构建比赛。其主要任务还是关系抽取。 
主要目的是构建关系抽取的多个baseline，并整理出结果。

也积累一些预处理文本的代码。

### 预处理上的问题
1. 标注是英文char级别的标注。text似乎也比较长。 tokenizer的选择比较重要。 如何把 分词结果 和 原来的标注统一在一起
得到根据token序列的标注结果。

    想法1： 记录每一个token开始和结束的位置。 如果完全匹配，label中的start一定是某一个token开始的位置，end 一定是某一个 token的结束。
    token的长度。应该是 各个token之间的和 + 空格数

    ###
    ***不停的加入关键词处理规则，head 就有 245 有1/4的数据被弃用了。很不好。


    想法2： 把label进行tokenize， 在tokenzed句子中，去找 这个lable—token字串。这么做会匹配得到很多结果。筛选结果还是要结合 原来的位置信息。

想想如何基本上克服tokenizer呢？
    1. transformers - bert_cased_base
    